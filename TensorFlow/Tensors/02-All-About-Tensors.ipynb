{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-0.29604465, -0.21134205],\n",
       "       [ 0.01063002,  1.5165398 ]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random Tensor\n",
    "\n",
    "random = tf.random.Generator.from_seed(10) # Seed is for reproducibility\n",
    "random = random.normal(shape = (2, 2))\n",
    "\n",
    "random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two random (But same) Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       " array([[ 0.88051325, -1.6833194 ,  0.86754173],\n",
       "        [-0.19625713, -1.322665  , -0.02279496],\n",
       "        [-0.1383193 ,  0.44207528, -0.7531523 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       " array([[ 0.88051325, -1.6833194 ,  0.86754173],\n",
       "        [-0.19625713, -1.322665  , -0.02279496],\n",
       "        [-0.1383193 ,  0.44207528, -0.7531523 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 3), dtype=bool, numpy=\n",
       " array([[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]])>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create two random (but the same) Tensors\n",
    "\n",
    "random_1 = tf.random.Generator.from_seed(20)\n",
    "random_1 = random_1.normal(shape = (3, 3))\n",
    "\n",
    "random_2 = tf.random.Generator.from_seed(20)\n",
    "random_2 = random_2.normal(shape = (3, 3))\n",
    "\n",
    "random_1, random_2, random_1 == random_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shufle the order of the elements in Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 8,  2, 10],\n",
       "       [ 5,  6,  1],\n",
       "       [ 4,  9,  3]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle a tensor (valuable for when you want to shuffle your data so the inherent order dosen't effect learning)\n",
    "\n",
    "not_shuffled = tf.constant([\n",
    "    [8, 2, 10],\n",
    "    [5, 6, 1],\n",
    "    [4, 9, 3]\n",
    "])\n",
    "\n",
    "not_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 4,  9,  3],\n",
       "       [ 8,  2, 10],\n",
       "       [ 5,  6,  1]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle our non-shuffled Tensor\n",
    "# Randomly shuffle a tensor along it's first dimension\n",
    "\n",
    "shuffle = tf.random.shuffle(not_shuffled)\n",
    "\n",
    "shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 8,  2, 10],\n",
       "       [ 5,  6,  1],\n",
       "       [ 4,  9,  3]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.random.set_seed(10)\n",
    "\n",
    "shuffle = tf.random.shuffle(not_shuffled, seed = 20)\n",
    "\n",
    "shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 4,  2],\n",
       "       [10,  9],\n",
       "       [ 7,  8]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_shuffled_1 = tf.constant([\n",
    "    [4, 2],\n",
    "    [10, 9],\n",
    "    [7, 8]\n",
    "])\n",
    "\n",
    "not_shuffled_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 4,  2],\n",
       "       [ 7,  8],\n",
       "       [10,  9]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(30)\n",
    "\n",
    "shuffled_1 = tf.random.shuffle(not_shuffled_1)\n",
    "\n",
    "shuffled_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. If neither the global seed nor the operation seed is set: A randomly picked seed is used for this op.\n",
    "##### 2. If the global seed is set, but the operation seed is not: The system deterministically picks an operation seed in conjunction with the global seed so that it gets a unique random sequence. Within the same version of tensorflow and user code, this sequence is deterministic. However across different versions, this sequence might change. If the code depends on particular seeds to work, specify both global and operation-level seeds explicitly.\n",
    "##### 3. If the operation seed is set, but the global seed is not set: A default global seed and the specified operation seed are used to determine the random sequence.\n",
    "##### 4. If both the global and the operation seed are set: Both seeds are used in conjunction to determine the random sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=int32, numpy=\n",
       "array([[6, 4, 1, 5, 7],\n",
       "       [7, 3, 8, 3, 1],\n",
       "       [5, 2, 1, 6, 8]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_shuffled_2 = tf.constant([\n",
    "    [5, 2, 1, 6, 8],\n",
    "    [6, 4, 1, 5, 7],\n",
    "    [7, 3, 8, 3,1]\n",
    "])\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "tf.random.shuffle(not_shuffled_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If we want our shuffled tensors to be in same order everytime, we've got to use both global and  operational level random seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to make tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create  a tensors of all ones\n",
    "\n",
    "tf.ones([10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float16, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float16)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensors of all zeros\n",
    "\n",
    "tf.zeros([2, 10], tf.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn numpy arrays into Tensors\n",
    "\n",
    "##### The main difference between numpy arrays and  tensorflow tensors is that tensors can be run on a GPU (much faster for numerical computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[4, 2, 5, 1],\n",
       "       [5, 1, 2, 5],\n",
       "       [0, 7, 4, 7]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "array_A = np.array([\n",
    "    [4, 2, 5, 1],\n",
    "    [5, 1, 2, 5],\n",
    "    [0, 7, 4, 7]\n",
    "])\n",
    "\n",
    "# X = tf.constant(some_matrix) :: variable name  is capital  because of matrix or Tensors\n",
    "# y = tf.constant(vector) :: smaller for vectors\n",
    "\n",
    "\n",
    "tensor_T = tf.constant(array_A)\n",
    "\n",
    "tensor_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array using arrange method\n",
    "\n",
    "array_A = np.arange(1, 25, dtype = np.int32) # Create a numpy array from 1 to 24, having float32 data type\n",
    "\n",
    "tensor_T = tf.constant(array_A)\n",
    "\n",
    "tensor_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15, 16],\n",
       "        [17, 18, 19, 20],\n",
       "        [21, 22, 23, 24]]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also change the shape of the tensor while converting numpy array to tensors\n",
    "\n",
    "tensor_T = tf.constant(array_A, shape = (2, 3, 4))\n",
    "\n",
    "tensor_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Information from tensors\n",
    "\n",
    "When dealing with tensors you probably want to be aware of the following attributes:\n",
    "\n",
    "* 1. Shape\n",
    "\n",
    "* 2. Rank\n",
    "\n",
    "* 3. Axis or Dimensions\n",
    "\n",
    "* 4. Size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 4 tensors(4 dimensions)\n",
    "\n",
    "rank_4_tensor = tf.zeros(shape = [2, 3, 4, 5])\n",
    "\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of every element in Tensor :  <dtype: 'float32'>\n",
      "Shape of Tensor :  (2, 3, 4, 5)\n",
      "Total number of elements in Tensor :  120\n",
      "Dimensions (Rank) of Tensor :  4\n",
      "Elements along the 0 axis :  2\n",
      "Elements along the last axis :  5\n"
     ]
    }
   ],
   "source": [
    "# Get various attributes of our tensors\n",
    "\n",
    "print(\"Datatype of every element in Tensor : \", rank_4_tensor.dtype)\n",
    "print(\"Shape of Tensor : \", rank_4_tensor.shape)\n",
    "print(\"Total number of elements in Tensor : \", tf.size(rank_4_tensor).numpy())\n",
    "print(\"Dimensions (Rank) of Tensor : \", rank_4_tensor.ndim)\n",
    "print(\"Elements along the 0 axis : \", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis : \", rank_4_tensor.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing Tensors\n",
    "\n",
    "Tensors can be indexed just like Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first two elements of each dimension\n",
    "\n",
    "rank_4_tensor[:2, :2, :2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1, 1), dtype=float32, numpy=\n",
       "array([[[[0.]]],\n",
       "\n",
       "\n",
       "       [[[0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first element from each dimension from each index except for the final one\n",
    "\n",
    "rank_4_tensor[:, :1, :1, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 2 tensor (2 dimensions)\n",
    "\n",
    "rank_2_tensor = tf.constant([\n",
    "    [10, 7],\n",
    "    [7, 10]\n",
    "])\n",
    "\n",
    "# Get the last time of eachof our rank 2 tensor\n",
    "\n",
    "rank_2_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 7],\n",
       "        [10]]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in extra dimension to our rank 2 Tensor\n",
    "\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis]\n",
    "\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 7],\n",
       "        [10]]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative of tf.newaxis\n",
    "\n",
    "tf.expand_dims(rank_2_tensor, axis = -1) # -1 means expand from end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[10,  7],\n",
       "        [ 7, 10]]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis = 0) # Expand 0th axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 7, 10]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original array is unchaged\n",
    "\n",
    "rank_2_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors(tensor operation)\n",
    "\n",
    "**Basic Operations**\n",
    "\n",
    "`+`, `-`, `*`, `/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[17, 20],\n",
       "       [15, 19]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can add values to tensors using addition operators\n",
    "\n",
    "tensor = tf.constant([\n",
    "    [7, 10],\n",
    "    [5, 9]\n",
    "])\n",
    "\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 7, 10],\n",
       "       [ 5,  9]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is unchanged\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10, 20],\n",
       "       [ 4,  8]])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "\n",
    "tensor = tf.constant([\n",
    "    [5, 10],\n",
    "    [2, 4]\n",
    "])\n",
    "\n",
    "tensor * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[2.5, 5. ],\n",
       "       [1. , 2. ]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division\n",
    "\n",
    "tensor / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[3, 8],\n",
       "       [0, 2]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction \n",
    "\n",
    "tensor - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[2.5, 5. ],\n",
       "       [1. , 2. ]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use tensorflow built-in functions\n",
    "\n",
    "tf.math.multiply(tensor, 10)\n",
    "\n",
    "tf.math.subtract(tensor, 2)\n",
    "\n",
    "tf.math.add(tensor, 10)\n",
    "\n",
    "tf.math.divide(tensor, 2)\n",
    "\n",
    "# It is recommended to use tensorflow buitl-in functions for speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "In machine learning, matrix multiplication is one of the most common tensor operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[58, 59],\n",
       "       [35, 28]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First create a simple tenosr\n",
    "\n",
    "arr = np.array([\n",
    "    [9, 8],\n",
    "    [0, 7]\n",
    "])\n",
    "\n",
    "tensor_1 = tf.constant(arr)\n",
    "\n",
    "tensor_2 = tf.constant([\n",
    "    [2, 3],\n",
    "    [5, 4]\n",
    "])\n",
    "\n",
    "tf.linalg.matmul(tensor_1, tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 22,  28],\n",
       "       [ 49,  64],\n",
       "       [ 76, 100]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(1, 10, dtype = np.int32)\n",
    "\n",
    "tensor_1 = tf.constant(arr, shape = (3, 3))\n",
    "\n",
    "arr = np.arange(1, 7, dtype = np.int32)\n",
    "\n",
    "tensor_2 = tf.constant(arr, shape = (3, 2))\n",
    "\n",
    "tf.matmul(tensor_1, tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 22,  28],\n",
       "       [ 49,  64],\n",
       "       [ 76, 100]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication using python operator \"@\"\n",
    "\n",
    "tensor_1 @ tensor_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the final shape of matrix after multiplication\n",
    "\n",
    "* First Matrix having shape (3, 4) == (x, y)\n",
    "\n",
    "* Second matrix having shape (4, 2) == (y, z)\n",
    "\n",
    "Result matrix shape is (3, 2) == (x, z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 9, 10, 11],\n",
       "       [39, 44, 49],\n",
       "       [69, 78, 87]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(0, 6)\n",
    "\n",
    "tensor_1 = tf.constant(arr, shape = (3, 2))\n",
    "\n",
    "arr = np.arange(6, 12)\n",
    "\n",
    "tensor_2 = tf.constant(arr, shape = (3, 2))\n",
    "\n",
    "# Let's change the shape of the tensor_2\n",
    "\n",
    "tensor_2 = tf.reshape(tensor_2, shape = (2, 3))\n",
    "\n",
    "tf.matmul(tensor_1, tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[0, 2, 4],\n",
       "        [1, 3, 5]])>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[0, 1, 2],\n",
       "        [3, 4, 5]])>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference between transpose and reshape\n",
    "\n",
    "tensor_1, tf.transpose(tensor_1), tf.reshape(tensor_1, shape = (2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Dot Product\n",
    "\n",
    "Matrix multiplication is also referred as the dot product:\n",
    "\n",
    "* `tf.matmul()`\n",
    "* `tf.tensordot()`\n",
    "* `@`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 9, 10, 11],\n",
       "       [39, 44, 49],\n",
       "       [69, 78, 87]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the dot product on the tensor_1 and tensor_2\n",
    "\n",
    "tf.tensordot(tensor_1, tensor_2, axes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, when performing matrix multiplication on two tensors and one of the axes dosen't line up,\n",
    "you will transpose (rather than reshape) one of the tensors to get satisfy the matrix multiplication rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the data type of the Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new Tensor with default data type (float32).\n",
    "\n",
    "A = tf.constant([1. , 4.])\n",
    "\n",
    "A.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = tf.constant([1, 2])\n",
    "\n",
    "B.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's change the data type from float32 to float16 (reduced precision)\n",
    "\n",
    "A = tf.cast(A, dtype = tf.float16)\n",
    "\n",
    "A.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, Change the data type from float16 to float32\n",
    "\n",
    "tf.cast(A, dtype = tf.float32).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Tensors\n",
    "\n",
    "Aggregating tensors = condensing them from multiple values down to a smaller amount of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-23. ,  12. ],\n",
       "       [  2.3,  -4.2]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant([\n",
    "    [-23, 12],\n",
    "    [2.3, -4.2]\n",
    "])\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[23. , 12. ],\n",
       "       [ 2.3,  4.2]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the absolute values\n",
    "\n",
    "tf.abs(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's go through the following forms of aggregation:\n",
    "\n",
    "* Get the minimum\n",
    "* Get the maximum\n",
    "* Get the mean of a Tensor\n",
    "* Get the sum of a Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: \n",
      " tf.Tensor(\n",
      "[12 72 92 33 78 75 76 12 87 37 18 43 36  4 96 44 82 37 27 92 29 45 15 14\n",
      " 81 54 99 10 66 72 44 47 39 50 40 40 72  1 49 42 67 44  9 19 25  7 88 96\n",
      " 63 95], shape=(50,), dtype=int32)\n",
      "\n",
      "Minimum From Tensor: \n",
      " tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "Maximum From Tensor: \n",
      " tf.Tensor(99, shape=(), dtype=int32)\n",
      "\n",
      "Mean From Tensor: \n",
      " tf.Tensor(49, shape=(), dtype=int32)\n",
      "\n",
      "Sum of the Tensor: \n",
      " tf.Tensor(2475, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant(np.random.randint(0, 100, size= 50))\n",
    "\n",
    "print(\"Original Tensor: \\n\", A)\n",
    "\n",
    "print(\"\\nMinimum From Tensor: \\n\", tf.math.reduce_min(A))\n",
    "\n",
    "print(\"\\nMaximum From Tensor: \\n\", tf.math.reduce_max(A))\n",
    "\n",
    "print(\"\\nMean From Tensor: \\n\", tf.math.reduce_mean(A))\n",
    "\n",
    "print(\"\\nSum of the Tensor: \\n\", tf.math.reduce_sum(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Muhammad Abu Bakar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Muhammad Abu Bakar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Muhammad Abu Bakar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "tf.Tensor(825, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=825.49>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the variance of the Tensor\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "print(tfp.stats.variance(A))\n",
    "\n",
    "tf.math.reduce_variance(tf.cast(A, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the positional maximum and minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new Tensor\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "A = tf.random.uniform(shape = [50])\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Maximum: \n",
      " tf.Tensor(42, shape=(), dtype=int64)\n",
      "\n",
      "Index on our largest value position: \n",
      " tf.Tensor(0.9671384, shape=(), dtype=float32)\n",
      "\n",
      "Compare max value and Positional maximum: \n",
      " tf.Tensor(True, shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Find positional maximum\n",
    "\n",
    "print(\"Positional Maximum: \\n\", tf.argmax(A))\n",
    "\n",
    "print(\"\\nIndex on our largest value position: \\n\", A[tf.argmax(A)])\n",
    "\n",
    "print(\"\\nCompare max value and Positional maximum: \\n\", A[tf.argmax(A)] == tf.math.reduce_max(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional minimum : \n",
      " tf.Tensor(16, shape=(), dtype=int64)\n",
      "\n",
      "Index on our smallest value in position: \n",
      " tf.Tensor(0.009463668, shape=(), dtype=float32)\n",
      "\n",
      "Compare min value and Positional minimum: \n",
      " tf.Tensor(True, shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Find Positional minimum\n",
    "\n",
    "print(\"Positional minimum : \\n\", tf.argmin(A))\n",
    "\n",
    "print(\"\\nIndex on our smallest value in position: \\n\", A[tf.argmin(A)])\n",
    "\n",
    "print(\"\\nCompare min value and Positional minimum: \\n\", A[tf.argmin(A)] == tf.math.reduce_min(A))\n",
    "\n",
    "assert A[tf.argmin(A)] == tf.reduce_min(A) # assert will give an error if it is not equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice of the Positional minimum and maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor : \n",
      " tf.Tensor(\n",
      "[2573 8273 7073 8384 7871 6892 3742 9310 8169 2100 2849 8117 6895 7166\n",
      " 5485 5251 8613 3600 8450 2507 2530 7177 3329 4715 7056 1472 2552 8480\n",
      " 4444 3917 8131 5296 9870 2943 5054 3636 7417 1587 9804 4679 4374 4490\n",
      " 3891 6919 7336 7207 6885 4991 5122 1421], shape=(50,), dtype=int32)\n",
      "\n",
      "Positional maximum : \n",
      " tf.Tensor(32, shape=(), dtype=int64)\n",
      "\n",
      "Positional minimum : \n",
      " tf.Tensor(49, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant(np.random.randint(1000, 10000, 50))\n",
    "\n",
    "print(\"Original Tensor : \\n\", A)\n",
    "\n",
    "print(\"\\nPositional maximum : \\n\", tf.argmax(A))\n",
    "\n",
    "print(\"\\nPositional minimum : \\n\", tf.argmin(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor : \n",
      " tf.Tensor(\n",
      "[[ 0.16052227 -1.6597689 ]\n",
      " [-1.232133    0.5971658 ]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "Positional maximum: \n",
      " tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "\n",
      "Positional minimum: \n",
      " tf.Tensor([1 0], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(100)\n",
    "\n",
    "B = tf.random.normal([2, 2])\n",
    "\n",
    "print(\"Original Tensor : \\n\", B)\n",
    "\n",
    "print(\"\\nPositional maximum: \\n\", tf.argmax(B))\n",
    "\n",
    "print(\"\\nPositional minimum: \\n\", tf.argmin(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezing a Tensor (Removing all single dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1, 1, 1, 50), dtype=float32, numpy=\n",
       " array([[[[[0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "            0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "            0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "            0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "            0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "            0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "            0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "            0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "            0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "            0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043]]]]],\n",
       "       dtype=float32)>,\n",
       " TensorShape([1, 1, 1, 1, 50]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "C = tf.constant(tf.random.uniform(shape = [50]), shape = (1, 1, 1, 1, 50))\n",
    "\n",
    "C, C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       " array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "        0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "        0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "        0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "        0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "        0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "        0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "        0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "        0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "        0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "       dtype=float32)>,\n",
       " TensorShape([50]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_squeezed = tf.squeeze(C) # squeeze remove dimensions of size 1 from the shape of a Tensor\n",
    "\n",
    "C_squeezed, C_squeezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of indices\n",
    "\n",
    "list = [0, 1, 2, 3] # could be red, green, blue, purple\n",
    "\n",
    "depth = list[tf.argmax(list)] + 1\n",
    "\n",
    "one_hot = tf.one_hot(list, depth)\n",
    "\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify custom values for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
       "array([[b'Yes', b'No', b'No', b'No'],\n",
       "       [b'No', b'Yes', b'No', b'No'],\n",
       "       [b'No', b'No', b'Yes', b'No'],\n",
       "       [b'No', b'No', b'No', b'Yes']], dtype=object)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = tf.one_hot(list, depth, on_value = 'Yes', off_value = 'No') # Can also use numbers in the on and off values\n",
    "\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math operations\n",
    "\n",
    "* Squaring\n",
    "* Log\n",
    "* Square Root\n",
    "* Power\n",
    "* Negative\n",
    "* Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = tf.range(0, 10)\n",
    "\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 0,  1,  4,  9, 16, 25, 36, 49, 64, 81])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square of the Tensor D\n",
    "\n",
    "D_square = tf.square(D)\n",
    "\n",
    "D_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=\n",
       "array([0.   , 1.   , 1.414, 1.732, 2.   , 2.236, 2.45 , 2.646, 2.828,\n",
       "       3.   ], dtype=float16)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square root of the Tensor D\n",
    "\n",
    "# D_square_root = tf.math.sqrt(D)  ERROR : Method requires non-int data type  \n",
    "\n",
    "D_square_root = tf.math.sqrt(tf.cast(D, dtype = tf.float16))\n",
    "\n",
    "D_square_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float16, numpy=\n",
       "array([  -inf, 0.    , 0.6934, 1.099 , 1.387 , 1.609 , 1.792 , 1.946 ,\n",
       "       2.08  , 2.197 ], dtype=float16)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log of the Tensor D\n",
    "\n",
    "# D_log = tf.math.log(D)  ERROR: Method requires non-int data type\n",
    "\n",
    "D_log = tf.math.log(tf.cast(D, dtype = tf.float16))\n",
    "\n",
    "D_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([9, 8, 7, 6, 5, 4, 3, 2, 1])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative\n",
    "\n",
    "E = tf.range(-9, 0)\n",
    "\n",
    "tf.math.negative(E)  # Compute numerical negative value element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 8, 9, 4])>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power\n",
    "\n",
    "X = tf.constant([1, 2, 3, 4])\n",
    "\n",
    "Y = tf.constant([4, 3, 2, 1])\n",
    "\n",
    "tf.math.pow(X, Y) # Computes the power of one value to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([3., 4.])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Real\n",
    "\n",
    "F = tf.constant([3 + 8j, 4 + 2j])\n",
    "\n",
    "tf.math.real(F) # Returns real part of the complex Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and NumPy\n",
    "\n",
    "Tensors interacts beautifully with NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor convert back to NumPy array: \n",
      " [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Type: \n",
      " <class 'numpy.ndarray'>\n",
      "\n",
      "Type: \n",
      " <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# Create tensor directly from numpy arrays\n",
    "\n",
    "G = tf.constant(np.arange(0, 9))\n",
    "\n",
    "# Convert Tensor back to NumPy array\n",
    "\n",
    "print(\"Tensor convert back to NumPy array: \\n\", np.array(G))\n",
    "\n",
    "print(\"\\nType: \\n\", type(np.array(G)))\n",
    "\n",
    "print(\"\\nType: \\n\", type(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8])>,\n",
       " tensorflow.python.framework.ops.EagerTensor,\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert G tensor into NumPy arrays\n",
    "\n",
    "G, type(G), G.numpy(), type(G.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default types of each are slightly different\n",
    "\n",
    "numpy_H = tf.constant(np.array([2, 2.]))\n",
    "\n",
    "tensor_H = tf.constant([2, 2.])\n",
    "\n",
    "# Check the data types of each\n",
    "\n",
    "numpy_H.dtype, tensor_H.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n",
       "       [ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20],\n",
       "       [ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30],\n",
       "       [ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40],\n",
       "       [ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50],\n",
       "       [ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60],\n",
       "       [ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70],\n",
       "       [ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80],\n",
       "       [ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90],\n",
       "       [ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array created\n",
    "arr = np.arange(1, 101)\n",
    "\n",
    "# Convert NumPy array into Tensor\n",
    "I = tf.constant(arr)\n",
    "\n",
    "# Now reshape Tensor\n",
    "I = tf.reshape(I, shape = (1, 10, 10, 1))\n",
    "\n",
    "# Now remove all one dimensions from the tensor\n",
    "I = tf.squeeze(I)\n",
    "\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we make numpy array using random mehtod\n",
    "arr = np.random.randint(0, 2, 30)\n",
    "\n",
    "# Convert numpy array into tensor\n",
    "J = tf.constant(arr)\n",
    "\n",
    "# Now, we one-hot encode this Tensor\n",
    "\n",
    "depth = arr[tf.argmax(arr)] + 1\n",
    "\n",
    "J = tf.one_hot(J, depth)\n",
    "\n",
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercises\n",
    "1. Create a vector, scalar, matrix and tensor w. ith values of your choosing using tf.constant().\n",
    "2. Find the shape, rank and size of the tensors.  you created in 1.\n",
    "3. Create two tensors containing random values . between 0 and 1 with shape [5, 300].\n",
    "4. Multiply the two tensors you created in 3 us. ing matrix multiplication.\n",
    "5. Multiply the two tensors you created in 3 us. ing dot product.\n",
    "6. Create a tensor with random values between 0.  and 1 with shape [224, 224, 3].\n",
    "7. Find the min and max values of the tensor yo. u created in 6.\n",
    "8. Created a tensor with random values of shape.  [1, 224, 224, 3] then squeeze it to change the shape to [224, 224, 3].\n",
    "9. Create a tensor with shape [10] using your o. wn choice of values, then find the index which has the maximum value.\n",
    "10. One-hot encode the tensor you created in 910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a vector, scalar, matrix and tensor w. ith values of your choosing using tf.constant().\n",
    "\n",
    "scalar = tf.constant(2)\n",
    "\n",
    "vector = tf.constant([5, 10])\n",
    "\n",
    "matrix = tf.constant([\n",
    "    [5, 10],\n",
    "    [10, 5]\n",
    "])\n",
    "\n",
    "Tensor = tf.constant([\n",
    "    [\n",
    "        [1, 2],\n",
    "        [3, 4]\n",
    "    ],\n",
    "    [\n",
    "        [5, 6],\n",
    "        [7, 8]\n",
    "    ]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALAR\n",
      "\n",
      "scalar shape:  ()\n",
      "\n",
      "scalar rank:  0\n",
      "\n",
      "scalar size:  tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "VECTOR\n",
      "\n",
      "vector shape:  (2,)\n",
      "\n",
      "vector rank:  1\n",
      "\n",
      "vector size:  tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "MATRIX\n",
      "\n",
      "matrix shape:  (2, 2)\n",
      "\n",
      "matrix rank:  2\n",
      "\n",
      "matrix size:  tf.Tensor(4, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "TENSOR\n",
      "\n",
      "Tensor shape:  (2, 2, 2)\n",
      "\n",
      "Tensor rank:  3\n",
      "\n",
      "Tensor size:  tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 2. Find the shape, rank and size of the tensors.  you created in 1.\n",
    "\n",
    "# Scalar\n",
    "\n",
    "print(\"SCALAR\")\n",
    "\n",
    "print(\"\\nscalar shape: \", scalar.shape)\n",
    "\n",
    "print(\"\\nscalar rank: \", scalar.ndim)\n",
    "\n",
    "print(\"\\nscalar size: \", tf.size(scalar))\n",
    "\n",
    "# Vector\n",
    "\n",
    "print(\"\\n\\nVECTOR\")\n",
    "\n",
    "print(\"\\nvector shape: \", vector.shape)\n",
    "\n",
    "print(\"\\nvector rank: \", vector.ndim)\n",
    "\n",
    "print(\"\\nvector size: \", tf.size(vector))\n",
    "\n",
    "# Matrix\n",
    "\n",
    "print(\"\\n\\nMATRIX\")\n",
    "\n",
    "print(\"\\nmatrix shape: \", matrix.shape)\n",
    "\n",
    "print(\"\\nmatrix rank: \", matrix.ndim)\n",
    "\n",
    "print(\"\\nmatrix size: \", tf.size(matrix))\n",
    "\n",
    "# Tensor\n",
    "\n",
    "print(\"\\n\\nTENSOR\")\n",
    "\n",
    "print(\"\\nTensor shape: \", Tensor.shape)\n",
    "\n",
    "print(\"\\nTensor rank: \", Tensor.ndim)\n",
    "\n",
    "print(\"\\nTensor size: \", tf.size(Tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 300), dtype=float64, numpy=\n",
       " array([[0.29298498, 0.3260656 , 0.24269316, ..., 0.18688763, 0.94121964,\n",
       "         0.93631441],\n",
       "        [0.52624151, 0.89508578, 0.7806746 , ..., 0.21445425, 0.41852687,\n",
       "         0.52538583],\n",
       "        [0.27811583, 0.62495325, 0.75899346, ..., 0.43375316, 0.4565087 ,\n",
       "         0.72961724],\n",
       "        [0.85420974, 0.67526664, 0.18703783, ..., 0.89531753, 0.97232674,\n",
       "         0.90242706],\n",
       "        [0.38383189, 0.56338666, 0.99655425, ..., 0.2365514 , 0.77318739,\n",
       "         0.78350802]])>,\n",
       " <tf.Tensor: shape=(5, 300), dtype=float64, numpy=\n",
       " array([[0.01106011, 0.40803138, 0.21996749, ..., 0.99024771, 0.86721526,\n",
       "         0.35816464],\n",
       "        [0.99118348, 0.72627491, 0.00496583, ..., 0.56753955, 0.89884497,\n",
       "         0.58088047],\n",
       "        [0.83812812, 0.40898245, 0.95229057, ..., 0.93521469, 0.78266321,\n",
       "         0.21252539],\n",
       "        [0.09215378, 0.40766095, 0.1033542 , ..., 0.93123808, 0.59725685,\n",
       "         0.4086864 ],\n",
       "        [0.86500355, 0.59631599, 0.32290254, ..., 0.26467185, 0.61082389,\n",
       "         0.13967349]])>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Create two tensors containing random values . between 0 and 1 with shape [5, 300].\n",
    "\n",
    "X = tf.constant(np.random.rand(5, 300))\n",
    "\n",
    "Y = tf.constant(np.random.rand(5, 300))\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float64, numpy=\n",
       "array([[67.47476675, 75.01338783, 74.47959945, 72.73301255, 72.69060614],\n",
       "       [69.51556439, 74.33247585, 74.74047982, 72.82359975, 73.85145418],\n",
       "       [66.12649171, 70.11072739, 72.31522807, 71.25736955, 70.38528813],\n",
       "       [67.43656939, 74.13863297, 75.48903971, 76.09569471, 75.16639042],\n",
       "       [73.05674976, 76.23361755, 79.3328778 , 73.96130312, 75.70766751]])>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Multiply the two tensors you created in 3 us. ing matrix multiplication.\n",
    "\n",
    "# Both are incompatible. so, first we reshape one of the tensor to make compatible for matrix multiplication\n",
    "\n",
    "Y = tf.reshape(Y, shape = (300, 5))\n",
    "\n",
    "result = tf.matmul(X, Y)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float64, numpy=\n",
       "array([[67.47476675, 75.01338783, 74.47959945, 72.73301255, 72.69060614],\n",
       "       [69.51556439, 74.33247585, 74.74047982, 72.82359975, 73.85145418],\n",
       "       [66.12649171, 70.11072739, 72.31522807, 71.25736955, 70.38528813],\n",
       "       [67.43656939, 74.13863297, 75.48903971, 76.09569471, 75.16639042],\n",
       "       [73.05674976, 76.23361755, 79.3328778 , 73.96130312, 75.70766751]])>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Multiply the two tensors you created in 3 us. ing dot product.\n",
    "\n",
    "tf.tensordot(X, Y, axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(244, 244, 3), dtype=float32, numpy=\n",
       "array([[[0.6645621 , 0.44100678, 0.3528825 ],\n",
       "        [0.46448255, 0.03366041, 0.68467236],\n",
       "        [0.74011743, 0.8724445 , 0.22632635],\n",
       "        ...,\n",
       "        [0.14993274, 0.95743346, 0.0678556 ],\n",
       "        [0.33755875, 0.2586832 , 0.31682265],\n",
       "        [0.12932086, 0.6521549 , 0.6951654 ]],\n",
       "\n",
       "       [[0.26241148, 0.36942792, 0.53326666],\n",
       "        [0.2040397 , 0.21521878, 0.48851562],\n",
       "        [0.5410471 , 0.55548096, 0.46440542],\n",
       "        ...,\n",
       "        [0.9536427 , 0.66850245, 0.50709856],\n",
       "        [0.560426  , 0.6647233 , 0.1626333 ],\n",
       "        [0.56197023, 0.4659928 , 0.8837141 ]],\n",
       "\n",
       "       [[0.67773116, 0.88375974, 0.7615204 ],\n",
       "        [0.53757155, 0.5554961 , 0.3356905 ],\n",
       "        [0.7514802 , 0.10988402, 0.46292984],\n",
       "        ...,\n",
       "        [0.28655422, 0.00708723, 0.39797664],\n",
       "        [0.32293415, 0.68600273, 0.2258904 ],\n",
       "        [0.3624704 , 0.2741145 , 0.6718725 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.1581651 , 0.0120461 , 0.37919486],\n",
       "        [0.5001323 , 0.8272053 , 0.22083938],\n",
       "        [0.3060074 , 0.79719913, 0.943571  ],\n",
       "        ...,\n",
       "        [0.87691283, 0.07822609, 0.02516437],\n",
       "        [0.76372766, 0.3627776 , 0.6275084 ],\n",
       "        [0.08343816, 0.27704644, 0.7373805 ]],\n",
       "\n",
       "       [[0.438125  , 0.6665685 , 0.17449224],\n",
       "        [0.22584939, 0.79596007, 0.5488591 ],\n",
       "        [0.22034144, 0.79884017, 0.62174785],\n",
       "        ...,\n",
       "        [0.08197904, 0.9438381 , 0.07644618],\n",
       "        [0.8251891 , 0.99572563, 0.9366641 ],\n",
       "        [0.22721207, 0.5737803 , 0.36763227]],\n",
       "\n",
       "       [[0.62615466, 0.08960044, 0.9523599 ],\n",
       "        [0.45630825, 0.18031716, 0.2717396 ],\n",
       "        [0.41115046, 0.77536   , 0.2236408 ],\n",
       "        ...,\n",
       "        [0.1636014 , 0.28872573, 0.04311168],\n",
       "        [0.30812   , 0.18930984, 0.7547977 ],\n",
       "        [0.91364396, 0.26925588, 0.77478504]]], dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Create a tensor with random values between 0.  and 1 with shape [224, 224, 3].\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "X = tf.random.uniform(shape = [244, 244, 3])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:  3.5762787e-07 \n",
      "\n",
      "max:  0.999998\n"
     ]
    }
   ],
   "source": [
    "#7. Find the min and max values of the tensor yo. u created in 6.\n",
    "\n",
    "min = tf.math.reduce_min(X).numpy()\n",
    "\n",
    "max = tf.math.reduce_max(X).numpy()\n",
    "\n",
    "print(\"min: \", min, \"\\n\\nmax: \", max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl Tensor:  (1, 224, 224, 3)\n",
      "\n",
      "Squeezed Tensor:  (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# 8. Created a tensor with random values of shape.  [1, 224, 224, 3] then squeeze it to change the shape to [224, 224, 3].\n",
    "\n",
    "Tensor = tf.random.uniform([1, 224, 224, 3])\n",
    "\n",
    "print(\"Origianl Tensor: \", Tensor.shape)\n",
    "\n",
    "# Now, we squeeze this Tensor\n",
    "\n",
    "squeezed_Tensor = tf.squeeze(Tensor)\n",
    "\n",
    "print(\"\\nSqueezed Tensor: \", squeezed_Tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=91>, 5)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Create a tensor with shape [10] using your own choice of values, then find the index which has the maximum value.\n",
    "\n",
    "Tensor = tf.constant([10, 4, 5, 12, 56, 91, 75, 32, 43, 90])\n",
    "\n",
    "max_index = tf.argmax(Tensor).numpy()\n",
    "\n",
    "Tensor[max_index], max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 92), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. One-hot encode the tensor you created in 9\n",
    "\n",
    "depth = Tensor[max_index] + 1\n",
    "\n",
    "Tensor_one_hot = tf.one_hot(Tensor, depth)\n",
    "\n",
    "Tensor_one_hot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
